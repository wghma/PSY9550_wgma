---
title: "PSY9550 Chapter 8"
author: "Alexandra & Winnie"
date: 04-09-2024     # Obs! American date format
format:
  html:
    toc: true
    toc-location: left
    embed-resources: true
    page-layout: full
    html-math-method: katex
editor: source
---

```{css, echo = F}
body{
  font-family: Helvetica;
  font-size: 16pt;
  max-width: 1000px;
  margin: auto;
  margin-left:310px;
}
pre{
  font-size: 14px;
}
/* Headers */
h1{
    font-size: 24pt;
  }
h1,h2{
    font-size: 20pt;
  }
h3,h4,h5,h6{
  font-size: 18pt;
}
#TOC {
  position: fixed;
  left: 0;
  top: 0;
  width: 300px;
  height: 100%;
  overflow:auto;
}
```

```{r setup,}
#| include: false
#| message: false
#| warning: false
#| results: hide
knitr::opts_chunk$set(echo = TRUE, dpi = 300)

library(rethinking)
library(magrittr)
library(tidyverse)
library(dagitty)
library(bayesplot)

Sys.setlocale("LC_ALL", 'en_US.UTF-8')

# add other packages you use here
```

# Clarification and or discussion questions

How to estimate a strictly negative beta_shade?

We do not know why, but using model1 gives a parameter table (precis) without the bs_log, all bs_logs are zero, and they are only found in the list mu \<- link(model1), mu is a list of bs_log and mu. But this does not happen with model2. Model2 results in a normal mu \<- link(model2), and precis(model2) includes all the parameters, BUT now bs_log is positive in the table.

```{r, eval = F}

model1 <- quap(
  alist(
    # the rest of the model...
     mu <- a + bw_log*water_cent + bs_log*shade_cent + bws*water_cent*shade_cent, 
   bs_log ~ (-1)*dlnorm( 0 , 0.5 )
   # have also tried bs_log ~ -dlnorm( 0 , 0.5 )
  )
)

# now with minus in the linear equation, instead of minus in the bs_log prior.
model2 <- quap(
  alist(
     # the rest of the model...
     mu <- a + bw_log*water_cent - bs_log*shade_cent + bws*water_cent*shade_cent, 
   bs_log ~ dlnorm( 0 , 0.5 )  # without *-1
  )
)

```

# Easy

## 8E1. Find hypothetical 3rd variable that could have an interaction effect

> **For each of the causal relationships below, name a hypothetical third variable that would lead to an interaction effect.**

> 1.  **Bread dough rises because of yeast.**
>
> 2.  **Education leads to higher income.**
>
> 3.  **Gasoline makes a car go.**

1.  A third variable for rising bread \~ yeast that could have an interaction effect, could be the amount of water or amount of salt in the dough or its temperature. Too little or too much water will inhibit rising, and too much salt will also inhibit growth. A dough will rise faster at higher temperatures, but may kill the yeast cells if it gets too hot, and a very low temperature will not activate the yeast. But none of this variables mean anything for the rising of dough if the yeast is not added.
2.  For the relation higher income \~ education, a third interaction variable could be the social networks/connections. That certain types of education or school may facilitate easier access to getting jobs or promotions that may increase the chances of a higher income, while the networking itself may a big factor in why that particular education was chosen in the first place.
3.  Gasoline and fire in the pistons make the car go. Third variable: the car's ability to fire the pistons.

## 8E2. Interaction yes or no?

> **Which of the following explanations invokes an interaction?**

> 1.  **Caramelizing onions requires cooking over low heat and making sure the onions do not dry out.**
>
> 2.  **A car will go faster when it has more cylinders or when it has better fuel injector.**
>
> 3.  **Most people acquire their political beliefs from their parents, unless they get them instead from their friends.**
>
> 4.  **Intelligent animal species tend to be either highly social or have manipulative appendages (hands, tentacles, etc.).**

1.  Yes, interaction between heat level and moisture content of onions.
2.  No, it is an either-this-or-that statement. By the statement it doesn't seem like there is a need for both more cylinders AND better fuel injector.
3.  No, also sounds like an either-this-or-that statement.
4.  No, also sounds like an either-this-or-that statement.

## 8E3 Make linear models

> **8E3. For each of the explanations in 8E2, write a linear model that expresses the stated relationship.**

1.  **Caramelizing onions requires cooking over low heat and making sure the onions do not dry out.**

    C = caramelized onions, H = heat, M = moisture

    $$
    C \sim N(\mu, \sigma)\\
    \mu = \alpha + (\beta_H+\beta_{HM}*M)*H + \beta_M*M
    $$

2.  **A car will go faster when it has more cylinders or when it has better fuel injector.**

    S = speed, C = number of cylinders, F = quality of fuel injector

    $$
    S \sim Normal(\mu, \sigma) \\
    \mu = \alpha + \beta_C*C + \beta_F*F
    $$

3.  **Most people acquire their political beliefs from their parents, unless they get them instead from their friends.**

    B = political beliefs, P = political beliefs of parents, F = political beliefs of friends

    $$
    P \sim Normal(\mu, \sigma) \\
    \mu = \alpha + \beta_P*P + \beta_F*F
    $$

4.  **Intelligent animal species tend to be either highly social or have manipulative appendages (hands, tentacles, etc.).**

I = intelligence, S = level of socialness, M = manipulate appendages

$$
I \sim Normal(\mu, \sigma) \\
\mu = \alpha + \beta_S*S + \beta_M*M
$$

# Medium

## 8M1 Blooming tulips and temperature

> **8M1. Recall the tulips example from the chapter. Suppose another set of treatments adjusted the temperature in the greenhouse over two levels: cold and hot. The data in the chapter were collected at the cold temperature. You find none of the plants grown under the hot temperature developed any blooms at all, regardless of the water and shade levels. Can you explain this result in terms of interactions between water, shade, and temperature?**

We knew from the example in book that water and shade had a symmetrical interaction effect, where the water contents effect on blooms was more positive with less shade, and vice versa. In this example we know that the hot greenhouse did not have any blooms regardless of adjustments in shade and water content. This indicates there are interaction effects between shade and temperature, and water and temperature.

## 8M2 Regression equation: tulips + temperature

> **8M2. Can you invent a regression equation that would make the bloom size zero, whenever the temperature is hot?**

B = Blooms, C= 0 when it is hot and 1 when cold, W = water, S = Shade

$$
B \sim Normal(\mu, \sigma) \\
\mu = C*(\alpha + \beta_W*W  + \beta_S*S + \beta_{WS}*W*S )
$$

## 8M3 Ravens and wolves (not answered)

**8M3. In parts of North America, ravens depend upon wolves for their food. This is because ravens are carnivorous but cannot usually kill or open carcasses of prey. Wolves however can and do kill and tear open animals, and they tolerate ravens co-feeding at their kills. This species relationship is generally described as a “species interaction.” Can you invent a hypothetical set of data on raven population size in which this relationship would manifest as a statistical interaction? Do you think the biological interaction could be linear? Why or why not?**

## 8M4 Tulips, regularized priors

**8M4. Repeat the tulips analysis, but this time use priors that constrain the effect of water to be positive and the effect of shade to be negative. Use prior predictive simulation. What do these prior assumptions mean for the interaction prior, if anything?**

```{r}
data("tulips")
# dataset = tulips
d <- tulips %>% 
  mutate(
    blooms_std =blooms / max(blooms), # scale 0 to 1
    water_cent = water - mean(water), # standardize -1 to 1
    shade_cent = shade - mean(shade), # standardize -1 to 1
  )

```

...more regularized priors for water (just positive) and shade (just negative).

```{r}
m8.8 <- quap( 
  alist( 
    blooms_std ~ dnorm( mu , sigma ),
    mu <- a + bw_log*water_cent - bs_log*shade_cent + bws*water_cent*shade_cent, 
    a ~ dnorm( 0.5 , 0.25 ) , 
    bw_log ~ dlnorm( 0 , 0.5 ) , # that water has a strictly positive relation to bloom
    bs_log ~ dlnorm( 0 , 0.5 ) ,  # that shade has a negative relation
    bws ~ dnorm( 0 , 0.25 ) ,
    sigma ~ dexp( 1 ) ), 
  data=d )
```

```{r}

# m8.8 <- quap(
#   alist(
#     blooms_std ~ dnorm( mu , sigma ),
#     mu <- a + bw_log*water_cent + bs_log*shade_cent + bws*water_cent*shade_cent,
#     a ~ dnorm( 0.5 , 0.25 ) ,
#     bw_log ~ dlnorm( 0 , 0.5 ) , # that water has a strictly positive relation to bloom
#     bs_log ~ -1*dlnorm( 0 , 0.5 ) ,  # that shade has a negative relation
#     bws ~ dnorm( 0 , 0.25 ) ,
#     sigma ~ dexp( 1 ) ),
#   data=d )

# Trying different ways of making bs_log strictly negative in the model.
# m8.8 <- quap(
#   alist(
#     blooms_std ~ dnorm( mu , sigma ),
#     mu <- a + bw_log*water_cent + bs_log*shade_cent + bws*water_cent*shade_cent,
#     a ~ dnorm( 0.5 , 0.25 ) ,
#     bw_log ~ dlnorm( 0 , 0.5 ) , # that water has a strictly positive relation to bloom
#     bs_log_pos ~ dlnorm( 0 , 0.5 ) ,  # that shade has a negative relation
#     bs_log <- bs_log_pos,
#     bws ~ dnorm( 0 , 0.25 ) ,
#     sigma ~ dexp( 1 ) ),
#   data=d )
```

```{r, echo = T, include = F}
# testing the log distribution
log_trekk <- -rlnorm(1e4, 0, 0.5)
hist(log_trekk)
# min(log_trekk)

```

Looking at the estimates of the parameters, the effect of water has a strictly positive relation to blooming, and shade has a strictly negative relation; the parameter is positive in the table, but has a negative sign in the linear equation. beta_shade then has a mean -0.15 and ranges between -0.20 and -0.11 for a 89% confidence interval.

The interaction term, between water and shade (bws), is strictly negative. Meaning the combined effect on blooming from both water and shade is reduced with more water or more shade, or both.

```{r}
precis(m8.8, depth = 2)
```

Prior predictive simulation. The slope of the lines seem very alike for all the three facets + seem very steep. It is interesting how for -1 shade there almost no lines where the x-axis (water) is above 0, and the opposite for shade 1 where there are few lines in the negative x values.

```{r}

prior <- extract.prior(m8.8)
par(mfrow=c(1,3)) # 3 plots in 1 row 

for ( s in -1:1 ) { 
  idx <- which( d$shade_cent==s ) #get the indixes of rows where s == TRUE. s = (-1:1)
  
  plot( d$water_cent[idx] , d$blooms_std[idx] , 
      xlim=c(-1,1) , ylim=c(0,1) , 
      xlab="water" , ylab="blooms" , 
      main = paste0("Shade ", s),
      pch=16 , col=rangi2 ) 

mu8.8 <- link( m8.8 , post=prior, data= data.frame( shade_cent=s , water_cent=-1:1 ) )

for ( i in 1:20 ) lines( x = -1:1 , y = mu8.8[i, ] , col=col.alpha("black",0.3) ) 

}


```

Posterior plotting show how the influence of the dataset "gather" the lines more compared to the priors.

```{r}
par(mfrow=c(1,3)) # 3 plots in 1 row 

for ( s in -1:1 ) { 
  idx <- which( d$shade_cent==s ) 
  plot( d$water_cent[idx] , d$blooms_std[idx] , 
        xlim=c(-1,1) , ylim=c(0,1) , 
        xlab="water" , ylab ="blooms" , 
        main = paste0("Shade ", s),
        pch=16 , col=rangi2 ) 

  mu <- link( m8.8 , data=data.frame( shade_cent=s , water_cent=-1:1 ) ) 
  
  # we sample 20 lines.
  for ( i in 1:20 ) 
    lines( -1:1 , mu[i,] , col=col.alpha("black",0.3) ) 

}
```
